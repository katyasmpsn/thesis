{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../results/cleaned_data.csv\")\n",
    "clusters = pd.read_csv(\"../results/clusters_both_100_30_01_27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = df.noteTextList.tolist() \n",
    "tweet_list = df.tweetTextList.tolist()\n",
    "\n",
    "note_list = [literal_eval(x) for x in note_list]\n",
    "tweet_list = [literal_eval(x) for x in tweet_list]\n",
    "\n",
    "\n",
    "word_list = note_list + tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_neighborhood_cts(word_list, i, window):\n",
    "    # INPUT: a list of tokens, a pointer for the key word, window size\n",
    "    # OUTPUT: a dictionary of counts for the neighborhood of the key word\n",
    "    pre_pane_li = i-window\n",
    "    pre_pane_ri = i\n",
    "    post_pane_li = i+1\n",
    "    post_pane_ri = i+1+window\n",
    "    if pre_pane_li < window  and i < window:\n",
    "        pre_pane_li = 0\n",
    "    if i == len(word_list) - 1:\n",
    "        pre_pane_li = len(word_list) - window - 1\n",
    "    neighborhood = word_list[pre_pane_li:pre_pane_ri] + word_list[post_pane_li:post_pane_ri]\n",
    "    inner_vecs = dict.fromkeys(set(neighborhood), 0)\n",
    "    for word in neighborhood:\n",
    "        inner_vecs[word] = inner_vecs[word] + 1\n",
    "    return inner_vecs\n",
    "\n",
    "master_class = {}\n",
    "total_ct = 0\n",
    "for l in word_list:\n",
    "    word_list = l\n",
    "    outer_vec = {}\n",
    "    for i in range(len(word_list)): # Looping thru all words\n",
    "        tmp = return_neighborhood_cts(word_list, i, window) # returning neighborhood counts for a key word\n",
    "        if (word_list[i] in outer_vec.keys()): # if a key word already has a dict entry, add to it\n",
    "            for k, v in tmp.items():\n",
    "                total_ct += v\n",
    "                try:\n",
    "                    outer_vec[word_list[i]][k] = outer_vec[word_list[i]][k] + v\n",
    "                except:\n",
    "                    outer_vec[word_list[i]][k] = v\n",
    "        else: # if a key word does not have a dict entry, create it\n",
    "            outer_vec[word_list[i]] = tmp\n",
    "            total_ct += sum(tmp.values())\n",
    "            \n",
    "    # updating the master dict over many documents\n",
    "    for k,v in outer_vec.items():\n",
    "        try:\n",
    "            master_class[k] = Counter(master_class[k]) + Counter(outer_vec[k])\n",
    "        except:\n",
    "            master_class[k] = outer_vec[k]\n",
    "\n",
    "\n",
    "# make every dict in the master dictionary a counter object such that when a co-occurence doesn't occur, the joint \n",
    "# probability == 0 \n",
    "\n",
    "master_class = {key: Counter(value) for key, value in master_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npmi(w1, w2, vectors, vector_ct):\n",
    "    # INPUT two words to compare, dict of vectors, total word count for denom\n",
    "    # OUTPUT ppmi for those two words\n",
    "    eps = 10**(-12)\n",
    "    # numerator\n",
    "    w1w2_dc = vectors[w1][w2] / vector_ct\n",
    "    w1_dc = sum(vectors[w1].values()) / vector_ct\n",
    "    w2_dc = sum(vectors[w2].values()) / vector_ct\n",
    "    \n",
    "    pmi_w1w2 = np.log((w1w2_dc) / ((w1_dc * w2_dc) + eps) + eps)\n",
    "    npmi_w1w2 = pmi_w1w2 / (- np.log( (w1w2_dc) + eps))\n",
    "    \n",
    "    return npmi_w1w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7869759"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters.groupby(['Cluster']).agg({\"Word_Type\": list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['back',\n",
       " 'close',\n",
       " 'run',\n",
       " 'break',\n",
       " 'leave',\n",
       " 'show',\n",
       " 'see',\n",
       " 'become',\n",
       " 'move',\n",
       " 'come']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = len(clusters)\n",
    "\n",
    "\n",
    "avg_npmis = []\n",
    "for i in range(cluster_ids):\n",
    "    test = clusters.iloc[i]['Word_Type']\n",
    "\n",
    "    npmi_scores = {}\n",
    "    for w1 in test:\n",
    "        npmi_sum = 0\n",
    "        ct = 0\n",
    "        for w2 in test:\n",
    "            if w1 != w2:\n",
    "                res = npmi(w1, w2, master_class, total_ct)\n",
    "    #             print(w1, w2, res)\n",
    "                npmi_sum += res\n",
    "                ct += 1\n",
    "            else:\n",
    "                pass\n",
    "        npmi_scores[w1] = npmi_sum/ct\n",
    "    \n",
    "    res = 0\n",
    "    for val in npmi_scores.values():\n",
    "        res += val\n",
    "  \n",
    "    # using len() to get total keys for mean computation\n",
    "    res = res / len(npmi_scores)\n",
    "    \n",
    "    final = (i,res)\n",
    "    avg_npmis.append(np.around((final),5))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word_Type    [putins, trumps, president, vladimir, obamas, ...\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.     , -0.67456]),\n",
       " array([ 1.     , -0.95011]),\n",
       " array([ 2.     , -0.28948]),\n",
       " array([ 3.     , -0.43293]),\n",
       " array([ 4.     , -0.08439]),\n",
       " array([ 5.     , -0.65637]),\n",
       " array([ 6.     , -0.48618]),\n",
       " array([ 7.     , -0.30972]),\n",
       " array([ 8.    , -0.7374]),\n",
       " array([ 9.     , -0.36714]),\n",
       " array([10.     , -0.54193]),\n",
       " array([11.     , -0.92604]),\n",
       " array([12.     , -0.45119]),\n",
       " array([13.     , -0.88198]),\n",
       " array([14.     , -0.66214]),\n",
       " array([15.     , -0.74918]),\n",
       " array([16.    , -0.8277]),\n",
       " array([17.     , -0.55288]),\n",
       " array([18., -1.]),\n",
       " array([19.     , -0.94647]),\n",
       " array([20.    , -0.7639]),\n",
       " array([21.     , -0.94433]),\n",
       " array([22.     , -0.87479]),\n",
       " array([23.     , -0.80176]),\n",
       " array([24.     , -0.89107]),\n",
       " array([25.     , -0.53321]),\n",
       " array([26.     , -0.46753]),\n",
       " array([27.     , -0.51146]),\n",
       " array([28.     , -0.37662]),\n",
       " array([29.     , -0.27219])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_npmis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.     , -0.67456]),\n",
       " array([ 1.     , -0.95011]),\n",
       " array([ 2.     , -0.28948]),\n",
       " array([ 3.     , -0.43293]),\n",
       " array([ 4.     , -0.08439]),\n",
       " array([ 5.     , -0.65637]),\n",
       " array([ 6.     , -0.48618]),\n",
       " array([ 7.     , -0.30972]),\n",
       " array([ 8.    , -0.7374]),\n",
       " array([ 9.     , -0.36714]),\n",
       " array([10.     , -0.54193]),\n",
       " array([11.     , -0.92604]),\n",
       " array([12.     , -0.45119]),\n",
       " array([13.     , -0.88198]),\n",
       " array([14.     , -0.66214]),\n",
       " array([15.     , -0.74918]),\n",
       " array([16.    , -0.8277]),\n",
       " array([17.     , -0.55288]),\n",
       " array([18., -1.]),\n",
       " array([19.     , -0.94647]),\n",
       " array([20.    , -0.7639]),\n",
       " array([21.     , -0.94433]),\n",
       " array([22.     , -0.87479]),\n",
       " array([23.     , -0.80176]),\n",
       " array([24.     , -0.89107]),\n",
       " array([25.     , -0.53321]),\n",
       " array([26.     , -0.46753]),\n",
       " array([27.     , -0.51146]),\n",
       " array([28.     , -0.37662]),\n",
       " array([29.     , -0.27219])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_npmis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}