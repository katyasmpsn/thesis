{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clusters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1986IMRZHKLaM7cX198ZDAl7mmgGoDkxx",
      "authorship_tag": "ABX9TyNVUDRTi+0aimHB8CzFzRtk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katyasmpsn/thesis/blob/main/clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kmpbbS4b2X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e19531-c46a-4ab2-b405-833f0a673bfe"
      },
      "source": [
        "# only run the install line below if the kernel has re-started \n",
        "# !pip install transformers\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "t = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§¹ Pre-Processing\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The note text has been pre-cleaned locally due to the size of the raw JSON blob. See `thesis/dev/thesis-rough-work.ipynb` \n",
        "\n",
        "1.   usernames, hashtags, urls, stopwords, punctuation, and digits omitted\n",
        "2.   Stop words removed \n",
        "\n",
        "**TO DO**: try without omitting stopwords. BERT might capture the \"unnaturalness\" of note text without stopwords \n",
        "\n"
      ],
      "metadata": {
        "id": "P3AIul6NNHy4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh_HKk7QcF29"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Thesis/cleaned_data.csv\")\n",
        "\"\"\"creating a column with a list of words for each text snippet so that it's easier to to calculate term frequencies over the corpus\"\"\"\n",
        "df['noteTextList'] = df['noteText'].str.lower().str.split()\n",
        "df = df[~df['noteTextList'].isnull()]  # why are there empty notes at this point? "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”¢ Corpus Statistics \n",
        "\n",
        "Sia et al found that using term frequency as their corpus statistic worked best. I'll also use term frequency with their notation\n",
        "\n",
        "tf $= \\frac{n_{t}}{\\Sigma_{t'}n_{t'}}$ where $n_{t}$ is the count of the word type $t$. \n"
      ],
      "metadata": {
        "id": "RM7q2YEKPuzk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbiRklqASwe7"
      },
      "source": [
        "# initializing Counter object \n",
        "vocab_counts = Counter()\n",
        "# updating the counter \n",
        "df['noteTextList'].apply(vocab_counts.update)\n",
        "corpus_denominator = sum(vocab_counts.values())\n",
        "# tf weights \n",
        "vocab_counts = {key:value/corpus_denominator for (key,value) in vocab_counts.items()}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’½ Generate Word Type Embeddings\n",
        "\n",
        "We get the last hidden state from BERT for each word token, using the entire note/tweet/reply as the context window. Then the embeddings are averaged over each word type. \n",
        "\n"
      ],
      "metadata": {
        "id": "bg89_sY6bGQU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmR42RcD2MQW"
      },
      "source": [
        "def getTokenEmbeddings(t1):\n",
        "  \"\"\"\n",
        "  INPUT: full text \n",
        "  OUTPUT: dictionary with each tokens last hidden state. If the original token \n",
        "  was broken down into subwords, the average over subword representations is\n",
        "  returned \n",
        "\n",
        "  {token : 1x768 vector}\n",
        "  \"\"\"\n",
        "\n",
        "  # this is possibly bad coding, `t` and `model` were instantiated outside of this function\n",
        "  # in the first code block \n",
        "\n",
        "  tokens = t(t1, return_attention_mask=False, return_token_type_ids=False)\n",
        "  words_ids = tokens.word_ids() \n",
        "\n",
        "  encoded_input = t(t1, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "\n",
        "  # Average subword representations \n",
        "  # Generate dummies for words_ids, multiply by the tensor\n",
        "  wi_d = pd.get_dummies(pd.Series(words_ids)).T\n",
        "  squeezed_states = torch.squeeze(output['last_hidden_state'])\n",
        "  reduced_states = torch.matmul(torch.from_numpy(wi_d.values.astype('float32')), squeezed_states)\n",
        "\n",
        "  words = t1.split()\n",
        "\n",
        "  res = {words[i]: reduced_states[i] for i in range(len(words))}\n",
        "  return res\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_data = [\"don't look up the comet can't be real\", \"look up everything is about to change because of the comet\"]\n",
        "fake = pd.DataFrame(fake_data, columns=[\"text\"])"
      ],
      "metadata": {
        "id": "18mYneuboBfx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.tweetText.tolist()"
      ],
      "metadata": {
        "id": "ZEqBF_yyu-v3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = fake.text.tolist()\n",
        "# so this is iterating through a list of text strings, and list of dicts [{t1_tok1: embed, t1_tok2: embed},{t2_tok1: embed, t2_tok2: embed}] \n",
        "text = [getTokenEmbeddings(x) for x in text]"
      ],
      "metadata": {
        "id": "ciiwJ0W8oCMU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just a toy function for now, but it's creating a master dictionary for the vocab. \n",
        "# in the example: \"look\" is used twice, and is in two separate dictionaries in `text`. \n",
        "# this adds all of the embeddings for \"look\" into one list\n",
        "d = {}\n",
        "for d_t in text: \n",
        "  for k,v in d_t.items():\n",
        "    try:\n",
        "      if d[k]:\n",
        "        d[k].append(v)\n",
        "    except KeyError:\n",
        "      d[k] = [v]\n",
        "\n",
        "# this now averages all of the embeddings for tokens that have more than one\n",
        "\n",
        "for k,v in d.items():\n",
        "  if len(v) > 1:\n",
        "    d[k] = [torch.mean(torch.stack(v), dim=0)]"
      ],
      "metadata": {
        "id": "rVvcPk30w6cp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[0][\"look\"].shape"
      ],
      "metadata": {
        "id": "5xk-ocn2zgs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eafea028-50e4-4ef2-e8a0-3242ff3162a0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[1][\"look\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGtbZskP1y3X",
        "outputId": "77783a7b-007d-4ee7-e08d-069912e4181e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"look\"][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLOF30GNIV8I",
        "outputId": "70b176b6-f935-4f07-da56-78c275e3090b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_list = [text[0][\"look\"], text[1][\"look\"]]\n",
        "mean = torch.mean(torch.stack(tensor_list), dim=0)\n"
      ],
      "metadata": {
        "id": "ZX5dywFcoCUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjx1-dlayi_E",
        "outputId": "50a43529-4463-4368-f273-e9596e03eeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text[1][\"look\"]"
      ],
      "metadata": {
        "id": "jkiVeXlhwxx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[1].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s8XF-rBoCbS",
        "outputId": "5a27727b-a9a0-49bf-e8ae-853b2301ac51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['look', 'up', 'everything', 'is', 'about', 'to', 'change', 'because', 'of', 'the', 'comet'])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "irg3p2ruqUjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccJjkoE4XYVP",
        "outputId": "1782628d-8704-4127-cd00-c1a6635ed0e5"
      },
      "source": [
        "embeddings_dict = defaultdict(list,{ k:[] for k in list(vocab_counts.keys()) })\n",
        "\n",
        "for t1 in notes[:2]:\n",
        "\n",
        "  tokens = t(t1, return_attention_mask=False, return_token_type_ids=False)\n",
        "  words_ids = tokens.word_ids() \n",
        "\n",
        "  encoded_input = t(t1, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "\n",
        "  ## Generate dummies for words_ids, multiply by the tensor\n",
        "  wi_d = pd.get_dummies(pd.Series(words_ids)).T\n",
        "  squeezed_states = torch.squeeze(output['last_hidden_state'])\n",
        "  reduced_states = torch.matmul(torch.from_numpy(wi_d.values.astype('float32')), squeezed_states)\n",
        "\n",
        "  words = t1.split()\n",
        "  print(words)\n",
        "  for i in range(len(words)):\n",
        "    embeddings_dict[words[i]].append(reduced_states[i])\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['blm', 'organization', 'terrorist', 'organization', 'approximately', 'percent', 'recent', 'blm', 'protests', 'peaceful', 'national', 'organization', 'specifically', 'calls', 'peaceful', 'protest']\n",
            "['post', 'claims', 'blm', 'organization', 'deserve', 'nobel', 'peace', 'prize', 'incited', 'violence', 'blm', 'organization', 'specifically', 'non-violent', 'explicitly', 'calls', 'page', 'vast', 'majority', 'blm', 'related', 'protests', 'us', 'peaceful']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CADa2TUqgqa",
        "outputId": "94d01a5f-74c4-4824-c825-6416601f051c"
      },
      "source": [
        "# not sure if I should average these or not \n",
        "torch.mean(torch.stack(embeddings_dict['organization']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0102, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7DvHOToOXbn0",
        "outputId": "b86d83ca-3b34-44f7-948a-0965a7493566"
      },
      "source": [
        "df.iloc[0]['noteText']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'blm organization terrorist organization approximately percent recent blm protests peaceful national organization specifically calls peaceful protest'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc3JNFrUnmqN"
      },
      "source": [
        "# getEmbeddings(df.iloc[0]['noteText'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS6jiXSvWmXY"
      },
      "source": [
        "tokens = t(t1, return_attention_mask=False, return_token_type_ids=False)\n",
        "words_ids = tokens.word_ids()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6A9m9JlW_f4",
        "outputId": "53bbbd4c-c145-4c30-96af-768e28c97992"
      },
      "source": [
        "words_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkoZW3146tGz",
        "outputId": "d014a8ec-4f3c-4d93-aa9a-f6eea02ba477"
      },
      "source": [
        "marked_text = \"[CLS] \" + \"bella is my cat\" + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = t.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "print (tokenized_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'bella', 'is', 'my', 'cat', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQgTDtARYI5c"
      },
      "source": [
        "encoded_input = t(t1, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb36u1PmOi8Q",
        "outputId": "925c8b0f-0642-4a55-b570-c00feb453c55"
      },
      "source": [
        "output['last_hidden_state'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POQwOxopyNSc"
      },
      "source": [
        "## Generate dummies for words_ids, multiply by the tensor\n",
        "wi_d = pd.get_dummies(pd.Series(words_ids)).T\n",
        "squeezed_states = torch.squeeze(output['last_hidden_state'])\n",
        "reduced_states = torch.matmul(torch.from_numpy(wi_d.values.astype('float32')), squeezed_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2qs-I_Ey_Uc",
        "outputId": "1b26fad6-d553-4b4c-c85f-f3d607354536"
      },
      "source": [
        "reduced_states.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([26, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAByYWfczAMU",
        "outputId": "d3e0fdf0-818a-49c1-cdc5-768787aedc40"
      },
      "source": [
        "wi_d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOa8B0sk0YC7"
      },
      "source": [
        "# words = t1.split()\n",
        "res = {words[i]: reduced_states[i] for i in range(len(words))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71a6odThMzAZ",
        "outputId": "547181ea-5d78-496e-c353-c5383f029310"
      },
      "source": [
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['post',\n",
              " 'claims',\n",
              " 'blm',\n",
              " 'organization',\n",
              " 'deserve',\n",
              " 'nobel',\n",
              " 'peace',\n",
              " 'prize',\n",
              " 'incited',\n",
              " 'violence',\n",
              " 'blm',\n",
              " 'organization',\n",
              " 'specifically',\n",
              " 'non-violent',\n",
              " 'explicitly',\n",
              " 'calls',\n",
              " 'page',\n",
              " 'vast',\n",
              " 'majority',\n",
              " 'blm',\n",
              " 'related',\n",
              " 'protests',\n",
              " 'us',\n",
              " 'peaceful']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-hgmrZL0eOP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi6ITotc1AaO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}